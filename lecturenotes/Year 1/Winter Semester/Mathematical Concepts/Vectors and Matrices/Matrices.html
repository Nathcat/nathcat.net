<!DOCTYPE html>
<html>
    <head>
        <title>Matrices</title>

        <script type="text/javascript"
            src="https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js">
        </script>
    </head>

    <body>
        <h1>Matrices</h1>
        <p>
            Matrices are often used to represent linear transformations on vectors, although they have many other applications
            as well, for example solving certain systems of equations.
        </p>

        <h2>Matrix-Matrix multiplication</h2>
        <p>
            Given two matrices 
            $\displaystyle{A:\mathbb{R}^n\to\mathbb{R}^m}$
            and 
            $\displaystyle{B:\mathbb{R}^m\to\mathbb{R}^k}$,
            we have:
        </p>
        <p>
            $\displaystyle{
                BA:\mathbb{R}^n\to\mathbb{R}^k
            }$
        </p>
        <p>
            $\displaystyle{
                \vec{x}\mapsto(BA)\vec{x}=B(A\vec{x})
            }$
        </p>
        <p>
            To multiply matrices, the number of columns in the first matrix
            must match the number of rows in the second matrix:
        </p>
        <p>
            $\displaystyle{
                \mathcal{M}(k,m)\times\mathcal{M}(m,n)\to\mathcal{M}(k,n)
            }$
        </p>
        <p>
            With the coefficients of the result matrix $C=BA$ being given by: 
            $\displaystyle{
                C_{ij}=\sum_{h=1}^mb_{ih}a_{hj}
            }$
        </p>
        <p>
            This operation is associative: $C(BA)=(CB)A$, but not commutative,
            so it <i><b>might</b></i> not be true that $AB=BA$, it might not even
            be possible to define both products.
        </p>
        <p>
            And multiplying with an identity matrix ($I_n\in\mathcal{M}(n,n)$):
        </p>
        <p>
            Let $A\in\mathcal{M}(m,n)$, $I_mA=A$ and $AI_n=A$
        </p>

        <h2>Rotation matrices</h2>
        <p>
            Matrices are very often used to define linear transformations, for
            example rotations on vectors:
        </p>
        <p>
            Rotation around $x$ : $\displaystyle{
                \left(
                \begin{array}{ccc}
                1&0&0\\
                0&\cos(\alpha)&\sin(\alpha)\\
                0&-\sin(\alpha)&\cos(\alpha)
                \end{array}    
                \right)
            }$
        </p>
        <p>
            Rotation around $y$ : $\displaystyle{
                \left(
                \begin{array}{ccc}
                \cos(\alpha)&0&\sin(\alpha)\\
                0&1&0\\
                -\sin(\alpha)&0&\cos(\alpha)
                \end{array}    
                \right)
            }$
        </p>
        <p>
            Rotation around $z$ : $\displaystyle{
                \left(
                \begin{array}{ccc}
                \cos(\alpha)&\sin(\alpha)&0\\
                -\sin(\alpha)&\cos(\alpha)&0\\
                0&0&1
                \end{array}    
                \right)
            }$
        </p>

        <h2>Matrix exponentiation</h2>
        <p>
            For $A=\mathcal{M}(n,n)$ we can define a notion of exponetiation on $A$.
        </p>
        <p>
            $\displaystyle{
                A^k=\{
                    \begin{array}{cc}
                    I_n&\mathrm{if } k=0\\
                    AA^{k-1}=A^{k-1}A&\mathrm{if } k>0
                    \end{array}
            }$
        </p>

        <h2>Matrix inverses</h2>
        <p>
            For $A,B\in\mathcal{M}(n,n)$, if $AB=BA=I_n$, we say that $B$ is
            the inverse of $A$, and write $B=A^{-1}$.
        </p>
        <p>
            For example: $\displaystyle{
                \left(
                \begin{array}{cc}
                2&-4\\ 0&2
                \end{array}    
                \right)

                \left(
                \begin{array}{cc}
                0.5&1\\ 0&0.5
                \end{array}    
                \right)
                =
                \left(
                \begin{array}{cc}
                2\cdot 0.5&2-4\cdot 0.5\\ 0&2\cdot 0.5
                \end{array}    
                \right)
                =
                \left(
                \begin{array}{cc}
                1&0\\0&1
                \end{array}    
                \right)
            }$
        </p>
        <p>
            Although sometimes the inverse of a matrix may simply not exist.
        </p>
        
        <h3>Row operations</h3>
        <p>
            We can try to build $A^{-1}$ by seeing how to transform $A$ into
            $I_n$ by "row reduction".
        </p>
        <p>
            However, reading the slides on this is confusing me so maybe we just
            stick to dividing by the determinant of the matrix:
        </p>
        <p>
            $A^{-1}=\frac{A}{det(A)}$
        </p>

        <h2>Determinant of a Matrix</h2>
        <p>
            The determinant can be defined as a recursive function with the
            following base case:
        </p>
        <p>
            $\displaystyle{
                A=\left[
                \begin{array}{cc}
                a&b\\c&d
                \end{array}
                \right]\to
                det\left(A\right)=ad-bc
            }$
        </p>
        <p>
            Look at a 3x3 matrix:
        </p>
        <p>
            $\displaystyle{
                A=\left[
                \begin{array}{ccc}
                a&b&c\\d&e&f\\g&h&i
                \end{array}
                \right]\to
                det\left(A\right)=a\left(ei-fh\right)-b\left(di-fg\right)+c\left(dh-eg\right)
            }$
        </p>
        <p>
            This is described nicely in the following links:
        </p>
        <ul>
            <li><a href="https://www.mathsisfun.com/algebra/matrix-determinant.html">Math Is Fun</a></li>
            <li><a href="https://en.wikipedia.org/wiki/Laplace_expansion">Laplace Expansion on Wikipedia</a></li>
        </ul>

        <p>
            The determinant only exists on square matrices.
        </p>

        <p>
            To describe this method (the Laplace expeansion), we must first look at what a minor is.
        </p>
        <p>
            A minor is the determinant of a sub-matrix of a matrix. This sub-matrix is obtained by removing one or more
            rows from the original matrix. So lets say that $M_{i,j}$ is the sub-matrix obtained by removing row $i$ and column
            $j$ from the matrix $M\in\mathcal{M}(n,n)$.
        </p>
        <p>
            For example, if
            $\displaystyle{
                M=\left(\begin{array}{ccc}
                a&b&c\\
                d&e&f\\
                g&h&i
                \end{array}\right)
            }$, then
            $m_{1,1}=\left(\begin{array}{cc}
            e&f\\
            h&i
            \end{array}\right)$, and
            $m_{1,2}=\left(\begin{array}{cc}
            d&f\\
            g&i
            \end{array}\right)$, and
            $m_{1,3}=\left(\begin{array}{cc}
            d&e\\
            g&h
            \end{array}\right)$
        </p>
        <p>
            Lets rewrite the 3x3 determinant in generalised way, using this information:
        </p>
        <p>
            $\displaystyle{\begin{array}{l}
                det\left(M\right)=a\left(ei-fh\right)-b\left(di-fg\right)+c\left(dh-eg\right)
                \\\to
                det\left(M\right)=A_{1,1}m_{1,1}-A_{1,2}m_{1,2}+A_{1,3}m_{1,3}
                \\\to
                det\left(M\right)=\left(-1\right)^{1+1}A_{1,1}m_{1,1}+\left(-1\right)^{1+2}A_{1,2}m_{1,2}+\left(-1\right)^{1+3}A_{1,3}m_{1,3}
                \\\to
                det\left(M\right)=\sum_{j=1}^n\left(-1\right)^{j+1}M_{1,j}m_{1,j}
            \end{array}}$
        </p>
        <p>
            As you can see, with matrices larger than 3x3 this becomes recursive, for example in a 4x4 matrix, the $m_{i,j}$
            is a 3x3 matrix, so you must then find the determinant of this 3x3 matrix to continue.
        </p>
        <p>
            There are of course other methods of finding the determinant, but personally I find that this one is the easiest to
            understand because it follows a very clear pattern.
        </p>
        <p>
            Also note that the determinant of a matrix may be denoted by $|M|.$
        </p>

        <h2>Final notes</h2>
        <p>An Orthogonal matrix is one which satisfies $A^T=A^{-1}$</p>
    </body>
</html>